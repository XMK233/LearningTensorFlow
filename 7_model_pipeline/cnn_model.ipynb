{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scale05.eecs.yorku.ca, 8881, d9559ffb6837ac01591fd79f187ae19c0f01304b8529b1c7"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Parameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import os\n",
    "import pandas as pd\n",
    "# https://pythonprogramming.net/cnn-tensorflow-convolutional-nerual-network-machine-learning-tutorial/\n",
    "# other cnn codes: https://www.datacamp.com/community/tutorials/cnn-tensorflow-python\n",
    "\n",
    "MODEL_SAVE_PATH = \"CNN_model/\"\n",
    "MODEL_NAME = \"cnn_model\"\n",
    "KEEP_RATE = 0.8\n",
    "\n",
    "N_CLASSES = 10\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "def performance_metrics1(confusion_matrix):\n",
    "    #https://blog.csdn.net/sihailongwang/article/details/77527970\n",
    "    #好像不一定对。值得斟酌。\n",
    "    \n",
    "    accu = [0 for i in range(N_CLASSES)]\n",
    "    column = [0 for i in range(N_CLASSES)]\n",
    "    line = [0 for i in range(N_CLASSES)]\n",
    "    accuracy = 0\n",
    "    recall = 0\n",
    "    precision = 0\n",
    "    for i in range(0, N_CLASSES):\n",
    "        accu[i] = confusion_matrix[i][i]\n",
    "    for i in range(0, N_CLASSES):\n",
    "       for j in range(0, N_CLASSES):\n",
    "           column[i]+=confusion_matrix[j][i]\n",
    "    for i in range(0, N_CLASSES):\n",
    "       for j in range(0, N_CLASSES):\n",
    "           line[i]+=confusion_matrix[i][j]\n",
    "    # for i in range(0, N_CLASSES):\n",
    "    #     accuracy += float(accu[i])/len_labels_all\n",
    "    for i in range(0, N_CLASSES):\n",
    "        if column[i] != 0:\n",
    "            recall+=float(accu[i])/column[i]\n",
    "    recall = recall /  N_CLASSES\n",
    "    for i in range(0, N_CLASSES):\n",
    "        if line[i] != 0:\n",
    "            precision+=float(accu[i])/line[i]\n",
    "    precision = precision /  N_CLASSES\n",
    "    f1_score = (2 * (precision * recall)) / (precision + recall)\n",
    "    print(\"Average Precision(AP): %f, \\n\"\n",
    "          \"Average Recall(AR): %f, \\n\"\n",
    "          \"F1 of AP and AR: %f\"\n",
    "          %(precision, recall, f1_score) \n",
    "    )\n",
    "    return precision, recall, f1_score\n",
    "\n",
    "def performance_metrics(confusion_matrix):\n",
    "    # 上一个方法precision和recall在行列关系上好像有点奇怪，可能弄反了。\n",
    "    # 而且计算的是各个类的平均值。\n",
    "    # 不过基本思想是对的，在弄清楚弄反与否之前暂时不要删掉前一个方法。\n",
    "    # 这个方法基本上是正统的计算方法了。而且会给出每一个类别的所有metrics。\n",
    "    # 行列代表的含义和该链接所述的相同：https://zhuanlan.zhihu.com/p/33273532\n",
    "    accu = [0 for i in range(N_CLASSES)]\n",
    "    column = [0 for i in range(N_CLASSES)]\n",
    "    line = [0 for i in range(N_CLASSES)]\n",
    "    for i in range(0, N_CLASSES):\n",
    "        accu[i] = confusion_matrix[i][i]\n",
    "    for i in range(0, N_CLASSES):\n",
    "       for j in range(0, N_CLASSES):\n",
    "           column[i]+=confusion_matrix[j][i]\n",
    "    for i in range(0, N_CLASSES):\n",
    "       for j in range(0, N_CLASSES):\n",
    "           line[i]+=confusion_matrix[i][j]\n",
    "    total_num = sum(line)\n",
    "    \n",
    "    for i in range(N_CLASSES):\n",
    "        TP = accu[i]\n",
    "        FP = column[i] - accu[i]\n",
    "        FN = line[i] - accu[i]\n",
    "        TN = total_num - TP - FP - FN\n",
    "        \n",
    "        recall = float(TP) / (TP + FN)\n",
    "        precision = float(TP) / (TP + FP)\n",
    "        f1_score = (2 * (precision * recall)) / (precision + recall)\n",
    "        print(\"For class %d: \\n\"\n",
    "            \"Average Precision(AP): %f, \\n\"\n",
    "            \"Average Recall(AR): %f, \\n\"\n",
    "            \"F1 of AP and AR: %f \\n\\n\"\n",
    "            %(i, precision, recall, f1_score) \n",
    "        )\n",
    "        \n",
    "\n",
    "def get_Batch1(data, label, batch_size):\n",
    "#https://blog.csdn.net/sinat_35821976/article/details/82668555 \n",
    "    x_batch = data.sample(batch_size)\n",
    "    y_batch = label.loc[list(x_batch.index)]\n",
    "    return x_batch, y_batch\n",
    "\n",
    "def get_Batch(data, label, batch_size):\n",
    "#https://blog.csdn.net/sinat_35821976/article/details/82668555 \n",
    "    print(data.shape, label.shape)\n",
    "    input_queue = tf.train.slice_input_producer([data, label], num_epochs=1, shuffle=True, capacity=32 ) \n",
    "    x_batch, y_batch = tf.train.batch(input_queue, batch_size=batch_size, num_threads=1, capacity=32, allow_smaller_final_batch=False)\n",
    "    return x_batch, y_batch\n",
    "\n",
    "class Dataset:\n",
    "    data = None\n",
    "    label = None\n",
    "    def __init__(self, path = \"train.csv\"):\n",
    "        df = pd.read_csv(path,header=0)\n",
    "        cols = df.columns.values.tolist()\n",
    "        cols.pop(0)\n",
    "        self.data = df[cols]\n",
    "        self.label = pd.get_dummies(df['label'])\n",
    "\n",
    "    def bi_split(self, percentage = 0.3):\n",
    "        length = round(len(self.data) * percentage)\n",
    "        \n",
    "        return self.data[0:length], self.label[0:length], \\\n",
    "               self.data[length + 1:], self.label[length + 1:]\n",
    "    \n",
    "    def tri_split(self, p1= 0.3, p2= 0.9):\n",
    "        l1 = round(len(self.data) * p1)\n",
    "        l2 = round(len(self.data) * p2)\n",
    "        \n",
    "        return self.data[0:l1], self.label[0:l1], \\\n",
    "                self.data[l1+1:l2], self.label[l1+1:l2], \\\n",
    "               self.data[l2+1:], self.label[l2+1:]"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Graph definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def maxpool2d(x):\n",
    "    #                        size of window         movement of window\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def convolutional_neural_network(x):\n",
    "    weights = {'W_conv1': tf.Variable(tf.random_normal([5, 5, 1, 32]), \n",
    "                                      name= 'W_conv1'),\n",
    "               'W_conv2': tf.Variable(tf.random_normal([5, 5, 32, 64]), \n",
    "                                      name = 'W_conv2'),\n",
    "               'W_fc': tf.Variable(tf.random_normal([7 * 7 * 64, 1024]), \n",
    "                                   name= 'W_fc'),\n",
    "               'out': tf.Variable(tf.random_normal([1024, N_CLASSES]), \n",
    "                                  name= 'out')}\n",
    "\n",
    "    biases = {'b_conv1': tf.Variable(tf.random_normal([32]),\n",
    "                                     name= 'b_conv1'),\n",
    "              'b_conv2': tf.Variable(tf.random_normal([64]), \n",
    "                                     name= 'b_conv2'),\n",
    "              'b_fc': tf.Variable(tf.random_normal([1024]), \n",
    "                                  name= 'b_fc'),\n",
    "              'out': tf.Variable(tf.random_normal([N_CLASSES]), \n",
    "                                 name= 'out')}\n",
    "\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "    conv1 = tf.nn.relu(conv2d(x, weights['W_conv1']) + biases['b_conv1'])\n",
    "    conv1 = maxpool2d(conv1)\n",
    "\n",
    "    conv2 = tf.nn.relu(conv2d(conv1, weights['W_conv2']) + biases['b_conv2'])\n",
    "    conv2 = maxpool2d(conv2)\n",
    "\n",
    "    fc = tf.reshape(conv2, [-1, 7 * 7 * 64])\n",
    "    fc = tf.nn.relu(tf.matmul(fc, weights['W_fc']) + biases['b_fc'])\n",
    "    fc = tf.nn.dropout(fc, KEEP_RATE)\n",
    "\n",
    "    output = tf.add(tf.matmul(fc, weights['out']), \n",
    "                    biases['out'], \n",
    "                    name= \"predict_output\")\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnd1, tnl1, tnd2, tnl2, tstd, tstl = Dataset().tri_split(0.45, 0.9)"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Initial training process definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network1(train_data, train_label, test_data, test_label):\n",
    "\n",
    "    x = tf.placeholder(tf.float32, [None, 784], name = \"x-input\")\n",
    "    y = tf.placeholder(tf.float32, name = \"y-input\")\n",
    "\n",
    "    prediction = convolutional_neural_network(x)\n",
    "    cost = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits= prediction, \n",
    "            labels= y),\n",
    "        name= \"cost\"\n",
    "    )\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "    hm_epochs = 3\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    with tf.control_dependencies([optimizer]):\n",
    "        train_op = tf.no_op(name='train')\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "        for epoch in range(hm_epochs):\n",
    "            epoch_loss = 0\n",
    "            for _ in range(int(len(train_data) / BATCH_SIZE)):\n",
    "                epoch_x, epoch_y = get_Batch1(train_data, \n",
    "                                             train_label, \n",
    "                                             BATCH_SIZE)\n",
    "                _, c = sess.run([train_op, cost], feed_dict={x: epoch_x, y: epoch_y})\n",
    "                epoch_loss += c\n",
    "\n",
    "            print('Epoch', epoch, 'completed out of', hm_epochs, 'loss:', epoch_loss)\n",
    "\n",
    "        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "        print('Accuracy:', accuracy.eval({x: test_data, y: test_label}))\n",
    "\n",
    "        saver.save(sess, os.path.join(MODEL_SAVE_PATH, MODEL_NAME))\n",
    "        saver.export_meta_graph(os.path.join(MODEL_SAVE_PATH, MODEL_NAME) + \".json\", as_text=True)\n",
    "        \n",
    "        confusion_matrix = tf.contrib.metrics.confusion_matrix(\n",
    "            tf.argmax(y, 1), \n",
    "            tf.argmax(prediction, 1)\n",
    "        )\n",
    "        cm = confusion_matrix.eval({x: test_data, \n",
    "                                 y: test_label}\n",
    "                                   )\n",
    "        print(cm)\n",
    "        return cm"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Run and save the initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks\nWARNING:tensorflow:From <ipython-input-4-1965eb3d8717>:10: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\n\nFuture major versions of TensorFlow will allow gradients to flow\ninto the labels input on backprop by default.\n\nSee `tf.nn.softmax_cross_entropy_with_logits_v2`.\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 completed out of 3 loss: 420182912.4375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed out of 3 loss: 91005708.5625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 completed out of 3 loss: 50683908.140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.91736126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[440   0   2   2   1   0   2   3   3   1]\n [  0 444   2   1   3   1   0   2   3   2]\n [  6   4 354   8   1   1   0   7   8   3]\n [  3   6  10 407   1   9   0   2   7   3]\n [  3   5   2   3 394   0   5   4   3  19]\n [  1   3   3   8   1 320   9   2   6   1]\n [  6   4   2   0   4   2 387   1   7   0]\n [  1   0   6   3   3   0   0 395   1  12]\n [  2  14   4  18   3   6   2   1 339   8]\n [  4   2   0   6   7   1   0  18   7 379]]\nFor class 0: \nAverage Precision(AP): 0.944206, \nAverage Recall(AR): 0.969163, \nF1 of AP and AR: 0.956522 \n\n\nFor class 1: \nAverage Precision(AP): 0.921162, \nAverage Recall(AR): 0.969432, \nF1 of AP and AR: 0.944681 \n\n\nFor class 2: \nAverage Precision(AP): 0.919481, \nAverage Recall(AR): 0.903061, \nF1 of AP and AR: 0.911197 \n\n\nFor class 3: \nAverage Precision(AP): 0.892544, \nAverage Recall(AR): 0.908482, \nF1 of AP and AR: 0.900442 \n\n\nFor class 4: \nAverage Precision(AP): 0.942584, \nAverage Recall(AR): 0.899543, \nF1 of AP and AR: 0.920561 \n\n\nFor class 5: \nAverage Precision(AP): 0.941176, \nAverage Recall(AR): 0.903955, \nF1 of AP and AR: 0.922190 \n\n\nFor class 6: \nAverage Precision(AP): 0.955556, \nAverage Recall(AR): 0.937046, \nF1 of AP and AR: 0.946210 \n\n\nFor class 7: \nAverage Precision(AP): 0.908046, \nAverage Recall(AR): 0.938242, \nF1 of AP and AR: 0.922897 \n\n\nFor class 8: \nAverage Precision(AP): 0.882812, \nAverage Recall(AR): 0.853904, \nF1 of AP and AR: 0.868118 \n\n\nFor class 9: \nAverage Precision(AP): 0.885514, \nAverage Recall(AR): 0.893868, \nF1 of AP and AR: 0.889671 \n\n\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(MODEL_SAVE_PATH):\n",
    "    os.mkdir(MODEL_SAVE_PATH)\n",
    "print(os.getcwd())\n",
    "\n",
    "# mnist dataset: https://blog.csdn.net/gaoyueace/article/details/79056085\n",
    "#mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "#train_neural_network(mnist)\n",
    "\n",
    "cm_origin = train_neural_network1(tnd1, tnl1, tstd, tstl)\n",
    "performance_metrics(cm_origin)\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Restore and continue training the model: Method definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_and_retrain_model1(input_checkpoint, \n",
    "                               train_data, train_label, \n",
    "                               test_data, test_label):\n",
    "\n",
    "    saver = tf.train.import_meta_graph(input_checkpoint + '.meta', \n",
    "                                       clear_devices=True)\n",
    "    # graph = tf.get_default_graph()  # 获得默认的图\n",
    "    # input_graph_def = graph.as_graph_def()  # 返回一个序列化的图代表当前的图\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, input_checkpoint)  # 恢复图并得到数据\n",
    "        graph = tf.get_default_graph()\n",
    "        cost = graph.get_tensor_by_name(\"cost:0\")\n",
    "        x = graph.get_tensor_by_name(\"x-input:0\")\n",
    "        y = graph.get_tensor_by_name(\"y-input:0\")\n",
    "        prediction = graph.get_tensor_by_name(\"predict_output:0\")\n",
    "        train_op = graph.get_operation_by_name(\"train\")\n",
    "        hm_epochs = 2\n",
    "        for epoch in range(hm_epochs):\n",
    "            epoch_loss = 0\n",
    "            for _ in range(int(len(train_data) / BATCH_SIZE)):\n",
    "                epoch_x, epoch_y = get_Batch1(train_data, train_label, \n",
    "                                              BATCH_SIZE)\n",
    "                _, c = sess.run([train_op, cost], feed_dict={x: \n",
    "                                                                 epoch_x, \n",
    "                                                             y: \n",
    "                                                                 epoch_y})\n",
    "                epoch_loss += c\n",
    "\n",
    "            print('Epoch', epoch, 'completed out of', hm_epochs, 'loss:', epoch_loss)\n",
    "\n",
    "        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "        print('Accuracy:', accuracy.eval({x: test_data, y: test_label}))\n",
    "\n",
    "        saver.save(sess, os.path.join(MODEL_SAVE_PATH, MODEL_NAME + \"_retrained\"))\n",
    "        saver.export_meta_graph(os.path.join(MODEL_SAVE_PATH, MODEL_NAME + \"_restrained\") + \".json\", as_text=True)\n",
    "\n",
    "        confusion_matrix = tf.contrib.metrics.confusion_matrix(\n",
    "            tf.argmax(y, 1), \n",
    "            tf.argmax(prediction, 1)\n",
    "        )\n",
    "        cm = confusion_matrix.eval({x: test_data, \n",
    "                                 y: test_label}\n",
    "                                   )\n",
    "        print(cm)\n",
    "        return cm"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Actually restore and retrain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from CNN_model/cnn_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 completed out of 2 loss: 40069308.93359375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed out of 2 loss: 26934773.8828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9316504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[440   0   2   0   1   3   2   0   5   1]\n [  0 438   2   3   2   1   1   4   6   1]\n [  4   1 350  12   1   2   1   6  13   2]\n [  2   1   4 423   0   3   1   5   8   1]\n [  2   0   0   2 407   0   5   6   3  13]\n [  4   0   0  11   3 320   6   0   6   4]\n [  2   0   0   0   2   1 402   0   6   0]\n [  0   0   4   2   2   1   0 404   2   6]\n [  3   8   5  13   2   3   5   1 351   6]\n [  5   0   1   4   8   1   1  22   5 377]]\nFor class 0: \nAverage Precision(AP): 0.952381, \nAverage Recall(AR): 0.969163, \nF1 of AP and AR: 0.960699 \n\n\nFor class 1: \nAverage Precision(AP): 0.977679, \nAverage Recall(AR): 0.956332, \nF1 of AP and AR: 0.966887 \n\n\nFor class 2: \nAverage Precision(AP): 0.951087, \nAverage Recall(AR): 0.892857, \nF1 of AP and AR: 0.921053 \n\n\nFor class 3: \nAverage Precision(AP): 0.900000, \nAverage Recall(AR): 0.944196, \nF1 of AP and AR: 0.921569 \n\n\nFor class 4: \nAverage Precision(AP): 0.950935, \nAverage Recall(AR): 0.929224, \nF1 of AP and AR: 0.939954 \n\n\nFor class 5: \nAverage Precision(AP): 0.955224, \nAverage Recall(AR): 0.903955, \nF1 of AP and AR: 0.928882 \n\n\nFor class 6: \nAverage Precision(AP): 0.948113, \nAverage Recall(AR): 0.973366, \nF1 of AP and AR: 0.960573 \n\n\nFor class 7: \nAverage Precision(AP): 0.901786, \nAverage Recall(AR): 0.959620, \nF1 of AP and AR: 0.929804 \n\n\nFor class 8: \nAverage Precision(AP): 0.866667, \nAverage Recall(AR): 0.884131, \nF1 of AP and AR: 0.875312 \n\n\nFor class 9: \nAverage Precision(AP): 0.917275, \nAverage Recall(AR): 0.889151, \nF1 of AP and AR: 0.902994 \n\n\n"
     ]
    }
   ],
   "source": [
    "#mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "cm_retrain = restore_and_retrain_model1(\"CNN_model/cnn_model\", tnd2, tnl2, tstd, tstl)\n",
    "performance_metrics(cm_retrain)"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Restore the first model and see the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_model1(input_checkpoint, \n",
    "                               test_data, test_label):\n",
    "    saver = tf.train.import_meta_graph(input_checkpoint + '.meta', \n",
    "                                       clear_devices=True)\n",
    "    # graph = tf.get_default_graph()  # 获得默认的图\n",
    "    # input_graph_def = graph.as_graph_def()  # 返回一个序列化的图代表当前的图\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, input_checkpoint)  # 恢复图并得到数据\n",
    "        \n",
    "        graph = tf.get_default_graph()\n",
    "        x = graph.get_tensor_by_name(\"x-input:0\")\n",
    "        y = graph.get_tensor_by_name(\"y-input:0\")\n",
    "        prediction = graph.get_tensor_by_name(\"predict_output:0\")\n",
    "        \n",
    "        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "        print('Accuracy:', accuracy.eval({x: test_data, y: test_label}))\n",
    "        \n",
    "        saver.save(sess, os.path.join(MODEL_SAVE_PATH, MODEL_NAME + \"_restored\"))\n",
    "        saver.export_meta_graph(os.path.join(MODEL_SAVE_PATH, MODEL_NAME + \"_restored\") + \".json\", as_text=True)\n",
    "        \n",
    "                \n",
    "        confusion_matrix = tf.contrib.metrics.confusion_matrix(\n",
    "            tf.argmax(y, 1), \n",
    "            tf.argmax(prediction, 1)\n",
    "        )\n",
    "        cm = confusion_matrix.eval({x: test_data, \n",
    "                                 y: test_label}\n",
    "                                   )\n",
    "        print(cm)\n",
    "        return cm"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Actually restore the model and see the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from CNN_model/cnn_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.91736126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[435   1   1   0   1   2   5   3   5   1]\n [  0 438   3   1   1   3   0   3   7   2]\n [  9   3 351   4   2   1   1   5  11   5]\n [  2   4   9 400   1  12   2   3  10   5]\n [  4   5   1   1 392   0   4   4   5  22]\n [  2   2   1  10   2 323   5   2   5   2]\n [  3   0   8   0   2   7 385   1   7   0]\n [  0   0   8   3   2   1   0 390   0  17]\n [  4   9   7  10   2   6   2   3 345   9]\n [  5   3   0   6   7   6   0  17   4 376]]\nFor class 0: \nAverage Precision(AP): 0.937500, \nAverage Recall(AR): 0.958150, \nF1 of AP and AR: 0.947712 \n\n\nFor class 1: \nAverage Precision(AP): 0.941935, \nAverage Recall(AR): 0.956332, \nF1 of AP and AR: 0.949079 \n\n\nFor class 2: \nAverage Precision(AP): 0.902314, \nAverage Recall(AR): 0.895408, \nF1 of AP and AR: 0.898848 \n\n\nFor class 3: \nAverage Precision(AP): 0.919540, \nAverage Recall(AR): 0.892857, \nF1 of AP and AR: 0.906002 \n\n\nFor class 4: \nAverage Precision(AP): 0.951456, \nAverage Recall(AR): 0.894977, \nF1 of AP and AR: 0.922353 \n\n\nFor class 5: \nAverage Precision(AP): 0.894737, \nAverage Recall(AR): 0.912429, \nF1 of AP and AR: 0.903497 \n\n\nFor class 6: \nAverage Precision(AP): 0.952970, \nAverage Recall(AR): 0.932203, \nF1 of AP and AR: 0.942472 \n\n\nFor class 7: \nAverage Precision(AP): 0.904872, \nAverage Recall(AR): 0.926366, \nF1 of AP and AR: 0.915493 \n\n\nFor class 8: \nAverage Precision(AP): 0.864662, \nAverage Recall(AR): 0.869018, \nF1 of AP and AR: 0.866834 \n\n\nFor class 9: \nAverage Precision(AP): 0.856492, \nAverage Recall(AR): 0.886792, \nF1 of AP and AR: 0.871379 \n\n\n"
     ]
    }
   ],
   "source": [
    "cm_restore = restore_model1(\"CNN_model/cnn_model\", tstd, tstl)\n",
    "performance_metrics(cm_restore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
