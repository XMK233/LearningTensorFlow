{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import matplotlib\n",
    "# matplotlib.use('TkAgg')\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.tools import inspect_checkpoint as chkp\n",
    "import os\n",
    "\n",
    "MODEL_SAVE_PATH = \"Reg_Model\"\n",
    "MODEL_NAME = \"model.ckpt\"\n",
    "SUMMARY_PATH = \"Reg_Logs\"\n",
    "TRAINING_STEPS = 100\n",
    "\n",
    "# 随机生成若干个点，围绕在y=0.1x+0.3的直线周围\n",
    "num_points = 100\n",
    "vectors_set = []\n",
    "for i in range(num_points):\n",
    "    x1 = np.random.normal(0.0, 0.55)\n",
    "    y1 = x1 * 0.1 + 0.3 + np.random.normal(0.0, 0.03)\n",
    "    vectors_set.append([x1, y1])\n",
    "\n",
    "# 生成一些样本\n",
    "x_data = [v[0] for v in vectors_set]\n",
    "y_data = [v[1] for v in vectors_set]\n",
    "\n",
    "plt.scatter(x_data, y_data, c='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Different Version of ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before training: \nW= [-0.7421026] b= [0.] loss= 0.2474321\n"
     ]
    }
   ],
   "source": [
    "# 生成1维W矩阵，取值是[-1, 1]之间的随机数\n",
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0), name='W')\n",
    "# 生成1维b矩阵，初始值是0\n",
    "b = tf.Variable(tf.zeros([1]), name='b')\n",
    "# 经过计算取得预估值y\n",
    "x = tf.placeholder(tf.float32, name= \"input\")\n",
    "y = tf.add(tf.multiply(W, x_data), b, name= \"output\")\n",
    "\n",
    "with tf.name_scope(\"loss_function\"): \n",
    "    # 以预估值y和实际值y_data之间的均方误差作为损失\n",
    "    loss = tf.reduce_mean(tf.square(y - y_data), name='loss')\n",
    "with tf.name_scope(\"training\"): \n",
    "    # 采用梯度下降法来优化参数\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "    # 训练的过程就是最小化这个误差值\n",
    "    train = optimizer.minimize(loss, name='train')\n",
    "\n",
    "sess = tf.Session()        #这种定义session的方法也可以，但是不推荐。\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# 初始化的w和b是多少\n",
    "print(\"before training: \")\n",
    "print(\"W=\", sess.run(W), \"b=\", sess.run(b), \"loss=\", sess.run(loss))\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "for step in range(3):\n",
    "    sess.run(train, feed_dict={x: x_data})\n",
    "    saver.save(sess, \n",
    "               os.path.join(MODEL_SAVE_PATH, MODEL_NAME), \n",
    "               global_step= step)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make the ckpts readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "#### 这个方法得到的模型不见得是对的，\n",
    "#### 建议：为了实验结果的精确，千万不要使用该方法\n",
    "#######################\n",
    "def transform_saved_graph_to_readable(model_path):\n",
    "    for model in os.listdir(model_path):\n",
    "        if \".meta\" in model:\n",
    "            saver = tf.train.import_meta_graph(os.path.join(model_path, model),\n",
    "                                               clear_devices=True)\n",
    "            saver.export_meta_graph(os.path.join(model_path, model) + \".json\", \n",
    "                                    as_text=True)\n",
    "            \n",
    "transform_saved_graph_to_readable(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## diff the models: graph and variable\n",
    "* graph: ignore_order = true\n",
    "* variable: ignore_order = false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph diff between ckpt 0 and 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable diff between ckpt 0 and 1\ngraph diff between ckpt 1 and 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable diff between ckpt 1 and 2\n"
     ]
    }
   ],
   "source": [
    "import re, json\n",
    "from deepdiff import DeepDiff\n",
    "\n",
    "def my_obj_pairs_hook(lst):\n",
    "    result={}\n",
    "    count={}\n",
    "    for key,val in lst:\n",
    "        if key in count:\n",
    "            count[key]=1+count[key]\n",
    "        else:\n",
    "            count[key]=1\n",
    "        if key in result:\n",
    "            if count[key] > 2:\n",
    "                result[key].append(val)\n",
    "            else:\n",
    "                result[key]=[result[key], val]\n",
    "        else:\n",
    "            result[key]=val\n",
    "    return result\n",
    "\n",
    "def formalize_json(file):\n",
    "    # model graph保存的文件不是正常的json格式，\n",
    "    # 这个方法将.meta转为正常json文件。\n",
    "    p1 = re.compile(\"[a-zA-Z_]+: \\\"\")\n",
    "    p2 = re.compile(\"[a-zA-Z_]+ {\")\n",
    "    p3 = re.compile(\"[a-zA-Z_]+: [\\w+-]+\")\n",
    "\n",
    "    lines = open(file, \"r\").readlines()\n",
    "    new_line = \"\"\n",
    "    for i in range(len(lines) - 1):\n",
    "        line = lines[i]\n",
    "        nline = lines[i + 1]\n",
    "        m1 = p1.findall(line)\n",
    "        m2 = p2.findall(line)\n",
    "        m3 = p3.findall(line)\n",
    "        l = line\n",
    "        if l[-1] == \"\\n\":\n",
    "            l = l[0:-1]\n",
    "        #remove the last \"\\n\"\n",
    "\n",
    "        if len(m2) > 0:\n",
    "            ori = m2[0].split()[0]\n",
    "            new = \"\\\"%s\\\":\" %(ori)\n",
    "            l = l.replace(ori, new)\n",
    "            new_line += l + \"\\n\"\n",
    "            continue\n",
    "        elif len(m1) > 0:\n",
    "            ori = m1[0].split(\":\")[0]\n",
    "            new = \"\\\"%s\\\"\" % (ori)\n",
    "            new1 = l.strip().replace((ori + \": \"), \"\").replace(\"\\\\\", \">|<\") ##这里要慎重\n",
    "            if ori == \"tensor_content\":\n",
    "                new1 = \"\\\"________\\\"\"##################new1.replace(\"\\\\\", \"_\")\n",
    "            l = new + \": \" + new1\n",
    "            new_line += l + (\",\" if nline.strip() != \"}\" else \"\") + \"\\n\"\n",
    "            continue\n",
    "        elif len(m3) > 0:\n",
    "            ori = m3[0].split(\": \")\n",
    "            new = [\"\\\"%s\\\"\" %(i) for i in ori]\n",
    "            l = \": \".join(new)\n",
    "            new_line += l + (\",\" if nline.strip() != \"}\" else \"\") + \"\\n\"\n",
    "            continue\n",
    "        else:\n",
    "            new_line += l + (\",\" if nline.strip() != \"}\" else \"\") + \"\\n\"\n",
    "    new_line += lines[-1]\n",
    "    return json.loads(\"{\" + new_line + \"}\", object_pairs_hook=my_obj_pairs_hook)\n",
    "\n",
    "def find_from_dict(dict, string):\n",
    "    # string looks like: \"root['PyTorch_CPU_MKL_Notebook']['awsmpConfig']['operatingSystems']['AMAZONLINUX']['aadistributionName']\",\n",
    "        tmp = dict\n",
    "        p = re.compile(\"\\'\\w+\\'\")\n",
    "        for i in p.findall(string):\n",
    "            tmp = tmp[i[1:-1]]\n",
    "        return tmp\n",
    "\n",
    "def show_diff_result(last_versions, curr_versions, result_json):\n",
    "    # 能够把一些diff结果显示出来\n",
    "    # result_json是他俩的原始diff结果的json形式\n",
    "    keys = result_json.keys()\n",
    "    for key in keys:\n",
    "        if key == \"dictionary_item_added\":\n",
    "            rms = result_json[key][\"py/set\"]\n",
    "            tmp_dict = {}\n",
    "            for rm in rms:\n",
    "                tt = find_from_dict(curr_versions, rm)\n",
    "                tmp_dict[rm] = tt\n",
    "            result_json[key] = tmp_dict\n",
    "            pass\n",
    "        elif key == \"dictionary_item_removed\":\n",
    "            ads = result_json[key][\"py/set\"]\n",
    "            tmp_dict = {}\n",
    "            for ad in ads:\n",
    "                tt = find_from_dict(last_versions, ad)\n",
    "                tmp_dict[ad] = tt\n",
    "            result_json[key] = tmp_dict\n",
    "            pass\n",
    "        else:\n",
    "            pass\n",
    "    return result_json\n",
    "\n",
    "def diff_models(model1_dir, model2_dir):\n",
    "    model1 = formalize_json(model1_dir)\n",
    "    model2 = formalize_json(model2_dir)\n",
    "    result = json.loads(DeepDiff(model1, model2).json)#, ignore_order=True\n",
    "    \n",
    "    # with open(\"diff_result.json\", \"w\") as dr:\n",
    "    #     json.dump(show_diff_result(model1, model2, result), dr, sort_keys=True, indent=4)\n",
    "    \n",
    "    return result\n",
    "    \n",
    "def variable_to_json(model_path):\n",
    "    reader = tf.train.NewCheckpointReader(model_path)\n",
    "    global_variables = reader.get_variable_to_shape_map()\n",
    "    \n",
    "    item = {}\n",
    "    for variable_name in global_variables:\n",
    "        item[variable_name] = {\"shape\": global_variables[variable_name],\n",
    "                               \"value\": reader.get_tensor(variable_name).tolist()}\n",
    "    \n",
    "    # with open(NAME + \".json\", \"w\") as v:\n",
    "    #     json.dump(item, v, sort_keys= True, indent= 4)#\n",
    "\n",
    "    return item\n",
    "\n",
    "def diff_varialbes(model1_dir, model2_dir):\n",
    "    return json.loads(DeepDiff(\n",
    "                variable_to_json(model1_dir),\n",
    "                variable_to_json(model2_dir)\n",
    "    ).json)\n",
    "        \n",
    "graph_dirs = []\n",
    "for name in os.listdir(MODEL_SAVE_PATH):\n",
    "    if \".json\" in name:\n",
    "        graph_dirs.append(name)\n",
    "\n",
    "for i in range(len(graph_dirs) - 1):      \n",
    "    print(\"graph diff between ckpt %d and %d\" %(i, i + 1)) \n",
    "    graph_diff = diff_models(os.path.join(MODEL_SAVE_PATH, graph_dirs[i]), \n",
    "                os.path.join(MODEL_SAVE_PATH, graph_dirs[i + 1]))\n",
    "    with open(\"graph_diff %d and %d.json\" %(i, i + 1), \"w\") as d:\n",
    "        json.dump(graph_diff, d, sort_keys= True, indent=2)\n",
    "\n",
    "    m1 = \".\".join(graph_dirs[i].split(\".\")[0:2])\n",
    "    m2 = \".\".join(graph_dirs[i + 1].split(\".\")[0:2])\n",
    "    print(\"variable diff between ckpt %d and %d\" %(i, i + 1))\n",
    "    variable_diff = diff_varialbes(os.path.join(MODEL_SAVE_PATH, m1), \n",
    "                       os.path.join(MODEL_SAVE_PATH, m2))\n",
    "    with open(\"variable_diff %d and %d.json\" %(i, i + 1), \"w\") as d:\n",
    "        json.dump(variable_diff, d, sort_keys= True, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
